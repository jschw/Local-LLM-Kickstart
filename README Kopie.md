# Local-LLM-Kickstart
A small GUI that starts a local OpenAI compatible inference endpoint using llama.cpp server.
